## 符号与定义

### 图/网络

网络可表示为$\mathcal G=(V,E)$。

邻接矩阵A是一个 $|V|*|V|$ 大小的矩阵，是边集的等价表示。

对于带权网络，可以表示为$\mathcal G=(V,E,W)$，指边带有权重。

对于符号网络，$\mathcal G$是只有正边、负边的网络，边的权值为$+1或-1$（仍然存在**无边**的情况）。

对于属性网络，可以表示为$\mathcal G=(V,E,X)$，指节点带有属性/特征。

对于动态网络，网络随时间t演化，可以表示为动态网络$\mathcal G_{(t)}=(V_t,E_t)$或时态网络$\mathcal G_{(t)}=(V,E,X_t)$。

### 社区

社区发现的最大挑战是：社区结构没有普遍定义。

社区是节点的集合，也可以看作网络的划分、图的子图、节点的聚类。

抽象（定性）地说，社区内部密集连接，社区间稀疏连接。

严谨（定量）地说，社区$C_i$应满足其内部节点$v_i$与社区内的度应大于社区外。

模块度（Modularity）是用于评估一个社区网络划分好坏的度量（社区发现研究历史上的里程碑），其思想是社区内部边的紧密程度比一个随机的网络/图要更紧密。模块度的一个优点是好坏与社区中点的数目无关。

下式表示，所有被划分到同一个社区的边所占的比例，再减除掉完全随机情况时被划分到同一个社区的边所占的比例。

$$
Q = \frac{1}{2m}\sum_{i,j}\left[{A_{ij}-\frac{k_ik_j}{2m}}\right]\delta(c_i,c_j)
$$

其中，$m=\frac{1}{2}\sum_{ij}A_{ij}$是所有边权之和，$c_i$表示节点i所属的社区，$k_i=\sum_jA_{ij}$。



![image-20220121232306042](%E7%BB%BC%E8%BF%B0.assets/image-20220121232306042.png)

重叠(overlapping)社区指存在$C_i \cap C_j \ne \varnothing$，即两个不同的社区之间有交集，一个节点可以属于多个社区；反之称社区是非重叠的(disjoint)。

![image-20220121232350653](%E7%BB%BC%E8%BF%B0.assets/image-20220121232350653.png)

## 社区发现的应用

分析社区在网络演化和社区影响，如谣言传播、病毒爆发和肿瘤进化。

- 引文网络：研究课题的重要性、相关性和演化性，研究趋势
- 企业网络：员工分组
- 社交网络：平台赞助商推广产品的目标用户
- 脑网络：不同脑分区的功能和指导解剖分离
- 代谢网络、蛋白质相互作用(PPI)网络：具有相似生物学功能的代谢和蛋白质

## 为什么要用深度学习来社区发现？

社区发现是一个NP-hard问题。

用一句话来概括：传统方法（谱聚类和统计推断）不行的，深度学习行！

进一步分解为两个问题：

1. 传统方法为什么不行？

- 传统方法在**小型、简单**网络中应用，而没有扩展到**大型**网络或具有高维特征的网络上；
- **计算及存储空间成本巨大**；
- 传统模型不能很好的处理**非线性结构信息**（现实世界的网络中大量存在）；
- 具体到技术层面，统计推断如SBM(stochastic block model)在高维复杂数据上表现不佳，机器学习算法如谱聚类(spectral clustering)在稀疏网络上表现一般。

2. 深度学习有哪些能力？

- 深度学习可以学习图数据的高度抽象表示，可以学习非线性特征，可以处理**图的高维复杂数据**。
- 图结构的数据  =转化=>  网络拓扑信息
- 学习节点、邻域、子图的pattern
- 对大规模网络的**稀疏性**更有弹性
- 现实世界数据无标签（关于数据中的社区没有先验知识），而深度学习适合无监督学习
- 除了网络拓扑外，可以将语义描述作为节点特征

## 分类法

社区发现的技术方法包括：CNN、GCN、Deep NMF、Deep SF、GAN、Auto-encoder、GAT、Community Embedding。从**多个视角（分类法）**来看社区发现有助于更好的理解，那么有哪些分类法来整理社区发现的技术？

可以从技术方法、网络类型、社区overlapping/disjoint。

### 从技术角度分类

第一种[^1]将社区发现分为了3种不同流派，分别是：

- DNN(deep neural networks) 
  - CNN（convolutional neural network）
  - Auto-encoder
  - GAN(generative adversarial network)
- NRL(deep graph embedding)
  - Deep NMF
  - Deep SF
  - Community Embedding

- GNN(graph neural networks)

[^1]:Deep Learning for Community Detection: Progress, Challenges and Opportunities

第二种[^2]将社区发现分为了：

- deep learning-based models upon deep neural networks
  - convolutional networks
    - CNN
    - GCN
  - GAT(graph attention networks)
  - GAN(generative adversarial networks)
  - Auto-encoder
  
- Deep NMF(deep nonnegative matrix factorization)

- Deep SF(deep sparse filtering)

[^2]:A Comprehensive Survey on Community Detection with Deep Learning

## 技术方法（框架、模型、算法）

### CNN

CNN = 卷积（减少计算复杂度）+ 池化（增强鲁棒性）

| 时间 作者   | 关键信息                   |
| ----------- | -------------------------- |
| 2017 Xin    | 拓扑不完备网络（观测缺失） |
| 2019 Sperli | 加入稀疏矩阵卷积           |

### Auto-encoder

| 时间 作者   | 关键信息                                                     |
| ----------- | ------------------------------------------------------------ |
| 2016 Yang   | Stacked auto-encoders 十分有效                               |
| 2018 Cao    | auto-encoder和谱聚类有相似的框架——低微近似（谱聚类PCA）      |
| 2018 Bhatia | 关注**网络拓扑**，随机游走（PageRank个性化？）+ fine-tune（优化社区结构的modularity） |
| 2018 Cao    | 利用上**节点属性**，Stacked auto-encoder                     |
| 2018 Cao    | 进一步匹配topology和节点属性，graph regularized auto-encoder（自适应参数作为匹配的权衡控制） |
| 2018 Bhatia | 避免了**预先设定社区数量**，设计了一个stack auto-encoder通过网络结构找社区中心 |
| 2018 Choong | 同样避免了**预先设定社区数量**，混合高斯算法（捕捉高阶模式）+建模网络生成的生成过程 |
| 2018 Shen   | 符号网络，半监督stack auto-encoder（重建邻接矩阵）学习有向网络的嵌入/表示 |

### GAN

生成对抗网络包括两个**相互竞争**的网络，**快速调整训练精度**，无监督，被证明在图表示任务上十分有效。

| 时间 作者 | 关键信息                                                     |
| --------- | ------------------------------------------------------------ |
| 2019 Jia  | dense overlapping社区，CommunityGAN联合解决了**重叠社区检测**和基于GAN的图表示学习，并且可表示成员关系强度。 |

### Deep NMF

非负矩阵分解（特征值和特征向量非负？），**近似**方法，最小化聚类任务的误差。

| 时间 作者 | 关键信息                       |
| --------- | ------------------------------ |
| 2018 Ye   | 将社区结构映射回初始网络       |
| 2018 Li   | 结合深度特征学习和深度网络嵌入 |

### Deep SF

嵌入可以编码邻接表（成对关系的输入），从而避免稀疏邻接矩阵。

SF稀疏滤波，只需要一个超参数。

| 时间 作者 | 关键信息                         |
| --------- | -------------------------------- |
| 2018 Xie  | 深度稀疏滤波，大规模网络社区发现 |

### Community Embedding 

网络中的社区反映了高阶近似性（有相似的观点或行为）

目标：学习低维空间中节点在社区中的分布。

| 时间 作者      | 关键信息                                                     |
| -------------- | ------------------------------------------------------------ |
| 2017 Cavallari | 社区嵌入有利于社区发现。利用节点分布来保留网络结构。         |
| 2018 Zhang     | community-preserving network embedding method                |
| 2019 Tu        | 同时学习节点和社区的嵌入，其优化过程在社区分配和节点嵌入之间交替进行，而不是同时解决两个任务。 |

### GNN/GCN

| 时间 作者   | 关键信息                                                     |
| ----------- | ------------------------------------------------------------ |
| 2019 Chen   | non-backtracking operator                                    |
| 2019 Jin    | GCN，马尔可夫随机场，属性网络，半监督                        |
| 2019 Shchur | Bernoulli–Poisson probabilistic model + GCN，overlapping社区发现 |

## 挑战/机会

1. 社区数量未知。问题：需要预先知道社区数量。机会：分析网络拓扑计算社区数量。
2. 层次网络。问题：提取分层表示，区分不同的关系类型，如水平和垂直关系，以及管理不同层次的稀疏性。
3. 异构网络（实体和关系类型存在显著差异的网络）。
4. 边上的符号信息（积极/消极）。
5. 社区嵌入。
6. 网络演变（拓扑、节点属性变化）。
7. 大规模网络。

## 随想

1. 图的高维复杂数据之间存在相关性，神经网络学习表示的强大能力正好有用，可以去除冗余，降低表示的维度。

## 问题汇总

1. **framework model algorithm 三者有什么区别？**
2. **综述告诉了我们什么？**不同流派的技术、现在的挑战、未来的机会。
3. 网络稀疏性指的是缺失missing（拓扑不完备topologically incomplete network）？还是实际数量就很少？
4. 节点、邻域、子图的pattern是什么玩意？
5. ###### semantic descriptions是什么玩意？