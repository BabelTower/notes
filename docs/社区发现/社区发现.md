## 为什么要用深度学习来社区发现？

用一句话来概括：传统方法（谱聚类和统计推断），不行！深度学习，行！

进一步分解为两个问题：

1. 传统机器学习为什么不行？

- 统计推断 stochastic block model 在高维复杂数据上表现不佳

- 传统机器学习算法将社区发现视为图上的聚类问题 （如spectral clustering在稀疏网络上表现较差）

2. 深度学习有哪些能力？

- 深度学习可以学习图数据的高度抽象表示，可以学习非线性特征，可以处理**图的高维复杂数据**。
- 图结构的数据  =转化=>  网络拓扑信息
- 学习节点、邻域、子图的pattern
- 对大规模网络的**稀疏性**更有弹性
- 现实世界数据无标签（关于数据中的社区没有先验知识），而深度学习适合无监督学习
- 除了网络拓扑外，可以将语义描述作为节点特征

## 分类法

社区发现的技术方法包括：CNN、GCN、Deep NMF、Deep SF、GAN、Auto-encoder、GAT、Community Embedding。从**多个视角（分类法）**来看社区发现有助于更好的理解，那么有哪些分类法来整理社区发现的技术？

### 从技术角度分类

第一种[^1]将社区发现分为了3种不同流派，分别是：

- DNN(deep neural networks) 
  - CNN（convolutional neural network）
  - Auto-encoder
  - GAN(generative adversarial network)
- NRL(deep graph embedding)
  - Deep NMF
  - Deep SF
  - Community Embedding

- GNN(graph neural networks)

[^1]:Deep Learning for Community Detection: Progress, Challenges and Opportunities

第二种[^2]将社区发现分为了：

- deep learning-based models upon deep neural networks
  - convolutional networks
    - CNN
    - GCN
  - GAT(graph attention networks)
  - GAN(generative adversarial networks)
  - Auto-encoder
  
- Deep NMF(deep nonnegative matrix factorization)

- Deep SF(deep sparse filtering)

[^2]:A Comprehensive Survey on Community Detection with Deep Learning

## 基础概念

### 社区

一组节点的聚类/子图，满足局部密集连接和高密度。

社区内部密集连接，社区间稀疏连接。用公式来表示的话就是：内部连接 > 外部连接。

社区发现是一个NP-hard问题，深度学习算法引入节点的属性来学习。

### 社区发现的应用

- PPI蛋白质相互作用网络
- 引文网络
- 企业网络
- 社交网络

## 技术方法（框架、模型、算法）

### CNN

CNN = 卷积（减少计算复杂度）+ 池化（增强鲁棒性）

| 时间 作者   | 关键信息                   |
| ----------- | -------------------------- |
| 2017 Xin    | 拓扑不完备网络（观测缺失） |
| 2019 Sperli | 加入稀疏矩阵卷积           |

### Auto-encoder

| 时间 作者   | 关键信息                                                     |
| ----------- | ------------------------------------------------------------ |
| 2016 Yang   | Stacked auto-encoders 十分有效                               |
| 2018 Cao    | auto-encoder和谱聚类有相似的框架——低微近似（谱聚类PCA）      |
| 2018 Bhatia | 关注**网络拓扑**，随机游走（PageRank个性化？）+ fine-tune（优化社区结构的modularity） |
| 2018 Cao    | 利用上**节点属性**，Stacked auto-encoder                     |
| 2018 Cao    | 进一步匹配topology和节点属性，graph regularized auto-encoder（自适应参数作为匹配的权衡控制） |
| 2018 Bhatia | 避免了**预先设定社区数量**，设计了一个stack auto-encoder通过网络结构找社区中心 |
| 2018 Choong | 同样避免了**预先设定社区数量**，混合高斯算法（捕捉高阶模式）+建模网络生成的生成过程 |
| 2018 Shen   | 符号网络，半监督stack auto-encoder（重建邻接矩阵）学习有向网络的嵌入/表示 |

### GAN

生成对抗网络包括两个**相互竞争**的网络，**快速调整训练精度**，无监督，被证明在图表示任务上十分有效。

| 时间 作者 | 关键信息                                                     |
| --------- | ------------------------------------------------------------ |
| 2019 Jia  | dense overlapping社区，CommunityGAN联合解决了**重叠社区检测**和基于GAN的图表示学习，并且可表示成员关系强度。 |

### Deep NMF

非负矩阵分解（特征值和特征向量非负？），**近似**方法，最小化聚类任务的误差。

| 时间 作者 | 关键信息                       |
| --------- | ------------------------------ |
| 2018 Ye   | 将社区结构映射回初始网络       |
| 2018 Li   | 结合深度特征学习和深度网络嵌入 |

### Deep SF

嵌入可以编码邻接表（成对关系的输入），从而避免稀疏邻接矩阵。

SF稀疏滤波，只需要一个超参数。

| 时间 作者 | 关键信息                         |
| --------- | -------------------------------- |
| 2018 Xie  | 深度稀疏滤波，大规模网络社区发现 |

### Community Embedding 

网络中的社区反映了高阶近似性（有相似的观点或行为）

目标：学习低维空间中节点在社区中的分布。

| 时间 作者      | 关键信息                                                     |
| -------------- | ------------------------------------------------------------ |
| 2017 Cavallari | 社区嵌入有利于社区发现。利用节点分布来保留网络结构。         |
| 2018 Zhang     | community-preserving network embedding method                |
| 2019 Tu        | 同时学习节点和社区的嵌入，其优化过程在社区分配和节点嵌入之间交替进行，而不是同时解决两个任务。 |

### GNN/GCN

| 时间 作者   | 关键信息                                                     |
| ----------- | ------------------------------------------------------------ |
| 2019 Chen   | non-backtracking operator                                    |
| 2019 Jin    | GCN，马尔可夫随机场，属性网络，半监督                        |
| 2019 Shchur | Bernoulli–Poisson probabilistic model + GCN，overlapping社区发现 |

## 挑战/机会

1. 社区数量未知。问题：需要预先知道社区数量。机会：分析网络拓扑计算社区数量。
2. 层次网络。问题：提取分层表示，区分不同的关系类型，如水平和垂直关系，以及管理不同层次的稀疏性。
3. 异构网络（实体和关系类型存在显著差异的网络）。
4. 边上的符号信息（积极/消极）。
5. 社区嵌入。
6. 网络演变（拓扑、节点属性变化）。
7. 大规模网络。

## 随想

1. 图的高维复杂数据之间存在相关性，神经网络学习表示的强大能力正好有用，可以去除冗余，降低表示的维度。

## 问题汇总

1. **framework model algorithm 三者有什么区别？**
2. **综述告诉了我们什么？**不同流派的技术、现在的挑战、未来的机会。
3. 网络稀疏性指的是缺失missing（拓扑不完备topologically incomplete network）？还是实际数量就很少？
4. 节点、邻域、子图的pattern是什么玩意？
5. semantic descriptions是什么玩意？