CV（网格）、NLP（序列）都是属于欧式空间的数据。CNN的核心是**平移不变性和参数共享**，RNN的核心是**门控和长短时记忆**。但他们都不适用于图数据。基于神经网络结合图结构数据，根据实现方法的不同，图神经网络可以分为空域和谱域两类。

谱域的基本思想总结来说，是将卷积推广到图上：借助**谱图理论（Spectral Graph Theory）**来实现在拓扑图上的卷积操作，大致步骤为将空域中的拓扑图结构通过**傅立叶变换**映射到谱域中并进行卷积，然后利用逆变换返回空域，从而完成了图卷积操作。这种方法有效解决了CNN依赖图像这些网格类数据平移不变性的局限，针对图这种维度无穷、具有置换不变性的数据类型定义了卷积操作。其中主要的模型包括：Spectral Network，ChebNet，GCN和AGCN等。

**把传统的傅里叶变换以及卷积迁移到Graph上来，核心工作其实就是把拉普拉斯算子的特征函数** $e^{-i\omega t}$ **变为Graph对应的拉普拉斯矩阵的特征向量**。傅立叶分析的一个重要目的是将一个给定的函数表示成一族给定的基底函数的和，而希尔伯特空间为傅立叶分析提供了一种有效的表述方式。希尔伯特空间（Hilbert Space）是有限维欧几里得空间的一个推广，是一个完备的内积空间，其定义了一个带有内积的完备向量空间。在希尔伯空间中，一个抽象元素通常被称为向量，它可以是一个复数或者函数。

图拉普拉斯算子作用在由图节点信息构成的向量 $f$上得到的结果等于图拉普拉斯矩阵和向量 $f$ 的点积。拉普拉斯矩阵反映了当前节点对周围节点产生扰动时所产生的累积增益，直观上也可以理解为某一节点的权值变为其相邻节点权值的期望影响，形象一点就是拉普拉斯矩阵可以刻画局部的平滑度。图的拉普拉斯矩阵的本质是邻接矩阵的散度的梯度，其中散度衡量了一个点处的向量场是被发射还是被吸收，或者说，对于散度为正的点，散度越大，意味着相应的向量场越强烈地在此**发散**，而对于散度为负的点，意味着相应的向量场在此**汇聚**。

GCN一代的层级传播公式为：$y=\sigma(Ug_\theta U^Tx)$，GCN二代引入 K 阶多项式，层级传播公式修改为$y=\sigma(\sum_{k=0}^{K-1}\theta_k L^k x)$，GCN三代取拉普拉斯算子的二阶近似函数$K=2,\lambda_{max}=2$，在此基础上定义了三种不同的卷积核，卷积核v1：$\theta_0x-\theta_1D^{-\frac{1}{2}}AD^{-\frac{1}{2}}x$，卷积核v2规范化参数避免过拟合采用**single parameter**：$I_N+D^{-\frac{1}{2}}AD^{-\frac{1}{2}}$，卷积核v3再次归一化避免过拟合**renormalization trick**：$\tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}$。

而空域的基本思想是是直接在空间上定义卷积操作，通过构建领域包括选择固定数量的邻居节点、排序找到的邻居节点和定义不同邻域大小的卷积核。空域的图卷积利用边的信息，对节点信息进行聚合，从而生成新的节点比表示。主要的模型有：PATCHY-SAN，GraphSAGE，DCNN和DGCN等。

GCN是transductive的，对于新节点（加入后会改变旧节点的表示）要重新训练整张网络；而GraphSAGE是inductive的，节点表示不是固定的，这种学习表示方法可以用在动态网络$\mathcal G_{(t)}=(V_t,E_t)$上。节点的embedding由其邻域节点的特征聚合而来，GraphSAGE就是这么一种框架，其节点的embedding随邻域的变化（包括节点特征和边连接的增减）而变化。GraphSAGE循环k轮聚合邻域特征，得到最终的节点embedding学习聚合函数的参数需要损失函数，根损失函数据任务目标设计，有监督用cross entropy，无监督应让临近节点有相似表示：$J_G(z_u)=-log(\sigma(z_u^Tz_v))-Q\cdot\Bbb E_{V_n\sim P_{n}(v)}\log{\sigma(-z_u^Tz_{v_n})}$。

聚合函数包括Mean、GCN、LSTM（20220123：LSTM学习包括了序列的先后顺序关系，而图学习中这种先后关系并不存在，即使用了随机打乱的技巧，这种聚合函数仍然不符合直觉/不合理，从直觉上我们应该公平的对待所有邻域，但在实验中LSTM在Reddit、PPI数据集上展现优秀的性能）、Pooling四种。GraphGCN的邻域采样是一阶的，通过不断stack层数来聚合更高阶邻域的特征（和GCN类似，层数K选择为2，邻域采样次数为20）。

从**空域的角度**也能更容易理解GCN公式的推导，也是从层级传播公式$f(H^{(l)},A)=\sigma(AH^{(l)}W^{(l)})$对所有邻域聚合的简单神经网络层，通过添加自环、对称归一化，递推到层级传播公式$f(H^{(l)},A)=\sigma({\hat D^{-\frac{1}{2}}}{\hat A}{\hat D^{-\frac{1}{2}}}H^{(l)}W^{(l)})$，其中$\hat A=A+I$表示特征聚合的过程中加上自身，$\hat D$是$\hat A$的度矩阵。

图学习利用到拓扑关系和节点属性两方面的信息，GCN局限于tranductive，且难以处理有向图。GCN和GAT都是将邻域的特征聚合到节点上，不同的是GCN利用拉普拉斯矩阵，GAT利用注意力系数。GAT分为两类：Global和Mask。前者对所有节点attention，但是未利用上连接性，且计算成本高昂；后者只对邻域注意力，DGL和论文中采用的都是这种。

本质上，GAT 只是将GCN的**标准化常数（对称归一化后的邻接矩阵）**替换为使用**注意力权重的邻居节点特征**聚合函数。GAT中的注意力机制使邻域的权重取决于节点特征，独立于拓扑结构。前三行计公式旨在计算**softmax归一化后的注意力系数**（GAT中采用的是拼接成对节点的embedding，即加性注意力），最后一行是基于注意力做邻域的aggregate。
$$
z_i^{(l)}=W^{(l)}h_i^{(l)},  \\ 
e_{ij}^{(l)} = LeakyReLU(\vec{a}^{(l)^T}(z_i^{(l)}||z_j^{(l)})), \\ 
a_{ij}^{(l)} = \frac{exp(e_{ij}^{(l)})}{\sum_{k\in \mathcal{N}(i)}exp(e_{ik}^{(l)})}, \\ 
h_i^{(l+1)}=\sigma(\sum_{j\in \mathcal{N}(i)}a_{ij}^{(l)}z_j^{(l)})
$$

此外采用的多头注意力机制(multi-head attention)， 运用了类似ensemble的方法，其拼接的公式如下：

$$
h_i'(K)=\Vert_{k=1}^K\sigma(\sum_{j\in\mathcal{N}_i}a_{ij}^kW^kh_j)
$$

---

社区结构是复杂网络共有的性质。社区发现的最大挑战是：社区结构没有普遍定义。社区是节点的集合，也可以看作网络的划分、图的子图、节点的聚类。抽象（定性）地说，社区内部密集连接，社区间稀疏连接。严谨（定量）地说，社区$C_i$应满足其内部节点$v_i$与社区内的度应大于社区外。

模块度（Modularity）是用于评估一个社区网络划分好坏的度量（社区发现研究历史上的里程碑），其思想是社区内部边的紧密程度比一个随机的网络/图要更紧密。模块度的一个优点是好坏与社区中点的数目无关。下式表示，所有被划分到同一个社区的边所占的比例，再减除掉完全随机情况时被划分到同一个社区的边所占的比例。

$$
Q = \frac{1}{2m}\sum_{i,j}\left[{A_{ij}-\frac{k_ik_j}{2m}}\right]\delta(c_i,c_j)
$$

其中，$m=\frac{1}{2}\sum_{ij}A_{ij}$是所有边权之和，$c_i$表示节点i所属的社区，$k_i=\sum_jA_{ij}$。

社区发现有多种多样的应用，可以分析社区在网络演化和社区影响，如谣言传播、病毒爆发和肿瘤进化。在引文网络中，帮组研究课题的重要性、相关性和演化性，研究趋势；在企业网络中帮助员工分组；在社交网络中，帮平台赞助商推广产品的目标用户；在脑网络，指导不同脑分区的功能和指导解剖分离；在代谢网络、蛋白质相互作用(PPI)网络中，分析具有相似生物学功能的代谢和蛋白质。

社区发现的方法可以分为三类：传统方法、深度学习方法、基于图神经网络的方法。

基于GNN的社区发现步骤如下：

1. 构建图数据，根据实际网络中的对象和关系，将对象映射为节点，关系映射为边，节点属性依据相关信息编码，得到其向量化描述，边同时代表着节点间的相似度，两个不能直接相连的节点，可以考虑加入最短路径等信息。
2. 定义GNN模型是如何信息传播和节点特征的更新方法。GNN模型有很多种变体，不同的GNN变体会选用不同的聚集函数，包括但不限于max、mean、sum等等，根据不同的图结构聚集函数起到相应的功效。信息传递的过程是将邻域节点的信息聚合到中心节点，通过特定的运算，用于更新下一层节点的表示。
3. 提取出特征节点后，为实现社区发现，采用相关算法进行分类或聚类。

GNN社区发现根据问题的定义分为重叠社区的检测和非重叠社区的检测。

非重叠社区发现指社区之间不相交，即一个节点对应一个社区。LGNN HTGCN

重叠社区是指真实网络中相交的社区结构，即一个节点对应多个社区，这种情况更加符合现实世界的组织规律。

社区发现面临的共同问题是社区的个数不确定。